{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables broadcast son variables de sólo lectura que se mandan una sola vez a cada nodo en lugar de ser enviadas con cada una de las tareas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo implementamos variables broadcast?\n",
    "### Cómo se define la variable broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir una variable broadcast necesitamos llamarla a través del contexto de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "broadcastVar = Broadcast(0)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Broadcast(0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val broadcastVar = sc.broadcast(Array(1, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo consultar la variable broadcast\n",
    "Para poder consultar su valor utilizamos el método value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, 2, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcastVar.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo se destruye una variable broadcast\n",
    "Antes de destruir una variable broadcast se sugiere qitar su persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcastVar.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ya después eliminarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcastVar.destroy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escenario hipotético 1\n",
    "Supongamos que queremos contar los elementos gramaticales de un párrafo y tenemos un Mapa de cada palabra con su categoría gramatical.\n",
    "\n",
    "Para ello, supongamos que tenemos un diccionario como este (si nos va bien):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dictionary = Map(man -> noun, is -> verb, mortal -> adjective)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(man -> noun, is -> verb, mortal -> adjective)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val dictionary = Map((\"man\"-> \"noun\"), (\"is\"->\"verb\"),(\"mortal\"->\"adjective\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos también que tenemos una función que cuenta cuántas veces encuentra estos elementos gramaticales en nuestro párrafo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getElementsCount: (word: String, dictionary: Map[String,String])(String, Int)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " def getElementsCount(word :String, dictionary:Map[String,String]):(String,Int) = {\n",
    "dictionary.filter{ case (wording,wordType) => wording.equals((word))}.map(x => (x._2,1)).headOption.getOrElse((\"unknown\" -> 1)) //some dummy logic\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y usamos esa función para contar cada elemento gramatical encontrado con un set de datos definido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words = ParallelCollectionRDD[0] at parallelize at <console>:31\n",
       "grammarElementCounts = ShuffledRDD[2] at reduceByKey at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[2] at reduceByKey at <console>:32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = sc.parallelize(Array(\"man\",\"is\",\"mortal\",\"mortal\",\"1234\",\"789\",\"456\",\"is\",\"man\"))\n",
    "val grammarElementCounts = words.map( word => getElementsCount(word,dictionary)).reduceByKey((x,y) => x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Hizo lo que queríamos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((noun,2), (unknown,3), (adjective,2), (verb,2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammarElementCounts.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sí, pero, aunque a nivel local está bien, puede ser problemático cuando lo queramos implementar en el clúster porque se requeriría ese diccionario en cada tarea en todos y cada uno de los ejecutores (tal vez un diccionariod e este tamaño no importa mucho, pero qué va  apasar cuando tengamos un diccionario de miles o decenas o centenas de miles de elementos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con broadcast\n",
    "Tengo el mismo diccionario, sólo que tengo que convertirlo en una variable broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "broadCastDictionary = Broadcast(3)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Broadcast(3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val broadCastDictionary = sc.broadcast(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos un poco nuestra función getElementsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getElementsCount: (word: String, dictionary: org.apache.spark.broadcast.Broadcast[Map[String,String]])(String, Int)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getElementsCount(word :String, dictionary:org.apache.spark.broadcast.Broadcast[Map[String,String]]):(String,Int) = {\n",
    "dictionary.value.filter{ case (wording,wordType) => wording.equals((word))}.map(x => (x._2,1)).headOption.getOrElse((\"unknown\" -> 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar del diccionario crudo pasamos el diccionario broadbast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words = ParallelCollectionRDD[3] at parallelize at <console>:33\n",
       "grammarElementCounts = ShuffledRDD[5] at reduceByKey at <console>:34\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[5] at reduceByKey at <console>:34"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = sc.parallelize(Array(\"man\",\"is\",\"mortal\",\"mortal\",\"1234\",\"789\",\"456\",\"is\",\"man\"))\n",
    "val grammarElementCounts = words.map( word => getElementsCount(word,broadCastDictionary)).reduceByKey((x,y) => x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((noun,2), (unknown,3), (adjective,2), (verb,2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammarElementCounts.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escenario hipotético 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "names = MapPartitionsRDD[14] at map at <console>:27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[14] at map at <console>:27"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val names = sc.textFile(\"names\").map(line => (line.split(\",\")(3),line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addresses = MapPartitionsRDD[26] at map at <console>:27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[26] at map at <console>:27"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val addresses = sc.textFile(\"address\").map(line => (line.split(\",\")(0),line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(001 -> 001,india,Dheli, 002 -> 002,usa,Springfield, 003 -> 003,india,Calcuta)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses.collect().toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((002,(Ursula,Fuentes,Berain,002,002,usa,Springfield)), (003,(Mariana,Orantes,Garcia,003,003,india,Calcuta)), (001,(Libertad,Badillo,Hernandez,001,001,india,Dheli)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.join(addresses).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, con el join anterior tanto names como addresses sufrirían de un shuffling en el clúster para poder llevar a cabo el join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternativa 1\n",
    "Mandando el RDD más pequeño a cada nodo del ejecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addressesMap = Map(001 -> 001,india,Dheli, 002 -> 002,usa,Springfield, 003 -> 003,india,Calcuta)\n",
       "joined = MapPartitionsRDD[37] at map at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[37] at map at <console>:32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val addressesMap = addresses.collect().toMap\n",
    "val joined = names.map(v=>(v._2,(addressesMap(v._1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array((Libertad,Badillo,Hernandez,001,001,india,Dheli), (Ursula,Fuentes,Berain,002,002,usa,Springfield), (Mariana,Orantes,Garcia,003,003,india,Calcuta))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto tampoco resuelve del todo la situación, ya que para cada tarea en cada nodo podríamos estar mandando una gran cantidad de datos, lo cual hace este procedimiento ineficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuentes teóricas y de los ejercicios\n",
    "* https://books.japila.pl/apache-spark-internals/apache-spark-internals/2.4.4/spark-broadcast.html\n",
    "* https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#broadcast-variables\n",
    "* https://blog.knoldus.com/broadcast-variables-in-spark-how-and-when-to-use-them/\n",
    "* http://www.prathapkudupublog.com/2018/06/accumulators-and-broadcast-variables-in.html\n",
    "* https://vishnuviswanath.com/spark_rdd_part2.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
